{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "1-attention-mechanism.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/dive-to-deep-learning/blob/main/10-attention-mechanisms/1_attention_mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xnl586bJ4d-"
      },
      "source": [
        "# Attention Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3sbSqlFKOmt"
      },
      "source": [
        "As a bit of a historical digression, attention research is an enormous field with a long history in cognitive neuroscience. Focalization, concentration of consciousness are of the essence of attention, which enable the human to prioritize the perception in order to deal effectively with others.\r\n",
        "\r\n",
        "As a result, we do not process all the information that is available in the sensory input. At any time, we are aware of only a small fraction of the information in the environment. In cognitive neuroscience, there are several types of attention such as selective attention, covert attention, and\r\n",
        "spatial attention. The theory ignites the spark in recent deep learning is the feature integration theory of the selective attention, which was developed by [Anne Treisman and Garry Gelade through the paper](https://www.sciencedirect.com/science/article/abs/pii/0010028580900055) in 1980. \r\n",
        "\r\n",
        "This paper declares that when perceiving a stimulus, features are registered early, automatically, and in parallel, while objects are identified separately\r\n",
        "and at a later stage in processing. The theory has been one of the most influential psychological models of human visual attention.\r\n",
        "\r\n",
        "In seq2seq, we encode the source sequence input information in the recurrent unit state and then pass it to the decoder to generate the target sequence. A token in the target sequence may closely relate to one or more tokens in the source sequence, instead of the whole source sequence.\r\n",
        "\r\n",
        "For example, when translating “Hello world.” to “Bonjour le monde.”, “Bonjour” maps to “Hello” and “monde” maps to “world”. **In the seq2seq model, the decoder may implicitly select the corresponding information from the state passed by the encoder. The attention mechanism, however, makes this selection explicit.**\r\n",
        "\r\n",
        "**Attention is a generalized pooling method with bias alignment over inputs. The core component in the attention mechanism is the attention layer, or called attention for simplicity. An input of the attention layer is called a query.**\r\n",
        "\r\n",
        "For a query, attention returns an output based on the memory—a set of key-value pairs encoded in the attention layer. To be more specific, assume that the memory contains $n$ key-value pairs, $(k_1; v_1),..., (k_n; v_n)$, with $k_i \\in\\mathbb R^{d_k} , v_i \\in\\mathbb R^{d_v}$ . Given a query $q \\in\\mathbb R^{d_q}$ , the attention layer returns an output $o \\in\\mathbb R^{d_v}$ with the same shape as the value.\r\n",
        "\r\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/attention-mechanism.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "To compute the output of attention, we first use a score function \u000b that measures the similarity between the query and the key. So for each key $k_1,.., k_n$, we compute the scores $a1,..,a_n$ by\r\n",
        "\r\n",
        "$$ a_i=\\alpha(q,k_i)$$\r\n",
        "\r\n",
        "Next we use softmax to obtain the attention weights, i.e.,\r\n",
        "\r\n",
        "$$ b = softmax(a), where, b_i={\\frac{exp(a_i)}{\\sum_j{exp(a_j)}}},b=[b_1,...,b_n]^T$$\r\n",
        "\r\n",
        "Finally, the output is a weighted sum of the values:\r\n",
        "\r\n",
        "$$o = \\sum_{i=1}^{n}b_iV_i$$\r\n",
        "\r\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/attention-output.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "Different choices of the score function lead to different attention layers. Below, we introduce two commonly used attention layers. Before diving into the implementation, we first express two operators to get you up and running: \r\n",
        "\r\n",
        "- a masked version of the softmax operator masked_softmax and\r\n",
        "- a specialized dot operator batch_dot.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yp25j50Tfv-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lze7GXsuKPez"
      },
      "source": [
        "!pip install -U mxnet-cu101==1.7.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-22T03:29:07.683798Z",
          "start_time": "2019-04-22T03:29:06.967885Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "1"
        },
        "id": "rx0AgdEKJ4eH"
      },
      "source": [
        "import math\n",
        "from mxnet import nd\n",
        "from mxnet.gluon import nn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt9Cku2tJ4eI"
      },
      "source": [
        "## Masked softmax attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSgkZMeFXd__"
      },
      "source": [
        "The masked softmax takes a 3-dimensional input and enables us to filter out some elements by specifying a valid length for the last dimension. As a result, any value outside the valid length will be masked as 0. Let us implement the\r\n",
        "masked_softmax function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-22T03:29:07.690646Z",
          "start_time": "2019-04-22T03:29:07.685803Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "6"
        },
        "id": "KINm9dTIJ4eJ"
      },
      "source": [
        "def masked_softmax(X, valid_length):\n",
        "  \"\"\"Perform softmax by filtering out some elements.\"\"\"\n",
        "\n",
        "  # X: 3-D tensor, valid_length: 1-D or 2-D tensor\n",
        "  if valid_length is None:\n",
        "      return X.softmax()\n",
        "  else:\n",
        "      shape = X.shape\n",
        "      if valid_length.ndim == 1:\n",
        "          valid_length = valid_length.repeat(shape[1], axis=0)\n",
        "      else:\n",
        "          valid_length = valid_length.reshape((-1,))\n",
        "      # fill masked elements with a large negative, whose exp is 0\n",
        "      X = nd.SequenceMask(X.reshape((-1, shape[-1])), valid_length, True, axis=1, value=-1e6)\n",
        "      return X.softmax().reshape(shape)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqH-TAj_J4eJ"
      },
      "source": [
        "We need to construct two 2X4 matrices as the input. In addition, we specify that the valid length equals to 2 for the first example, and 3 for the second example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-22T03:29:07.714655Z",
          "start_time": "2019-04-22T03:29:07.692276Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_vtazwpJ4eK",
        "outputId": "5440ed69-8f28-4aaa-a0c1-e03064543aee"
      },
      "source": [
        "masked_softmax(nd.random.uniform(shape=(2,2,4)), nd.array([2,3]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[[0.488994   0.511006   0.         0.        ]\n",
              "  [0.4365484  0.56345165 0.         0.        ]]\n",
              "\n",
              " [[0.288171   0.3519408  0.3598882  0.        ]\n",
              "  [0.29034296 0.25239873 0.45725837 0.        ]]]\n",
              "<NDArray 2x2x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJT_PFDwfuzt"
      },
      "source": [
        "Then, as we can see from the following outputs, the values outside valid lengths are masked as zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lUm2t1eJ4eL"
      },
      "source": [
        "## Dot Product Attention\n",
        "\n",
        "$$\\alpha(\\mathbf Q, \\mathbf K) = \\langle \\mathbf Q, \\mathbf K^T \\rangle /\\sqrt{d}.$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-22T03:29:07.727322Z",
          "start_time": "2019-04-22T03:29:07.722556Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "id": "UlUS6WJ9J4eL"
      },
      "source": [
        "class DotProductAttention(nn.Block):  \n",
        "    def __init__(self, dropout, **kwargs):\n",
        "        super(DotProductAttention, self).__init__(**kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # query: (batch_size, #queries, d)\n",
        "    # key: (batch_size, #kv_pairs, d)\n",
        "    # value: (batch_size, #kv_pairs, dim_v)\n",
        "    # valid_length: either (batch_size, ) or (batch_size, seq_len) \n",
        "    def forward(self, query, key, value, valid_length=None):\n",
        "        d = query.shape[-1]\n",
        "        # set transpose_b=True to swap the last two dimensions of key\n",
        "        scores = nd.batch_dot(query, key, transpose_b=True) / math.sqrt(d)\n",
        "        attention_weights = self.dropout(masked_softmax(scores, valid_length))\n",
        "        return nd.batch_dot(attention_weights, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r9X5dh6J4eM"
      },
      "source": [
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-22T03:29:07.736918Z",
          "start_time": "2019-04-22T03:29:07.728641Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "6"
        },
        "id": "KITMa17kJ4eM",
        "outputId": "8c447740-2612-402b-f995-d4d3da337635"
      },
      "source": [
        "atten = DotProductAttention(dropout=0.5)\n",
        "atten.initialize()\n",
        "keys = nd.ones((2,10,2))\n",
        "values = nd.arange(40).reshape((1,10,4)).repeat(2,axis=0)\n",
        "atten(nd.ones((2,1,2)), keys, values, nd.array([2, 6]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[[ 2.        3.        4.        5.      ]]\n",
              "\n",
              " [[10.       11.       12.000001 13.      ]]]\n",
              "<NDArray 2x1x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHjtUOAZJ4eM"
      },
      "source": [
        "## Multilayer Perception Attention\n",
        "\n",
        "$\\mathbf W_k\\in\\mathbb R^{h\\times d_k}$, $\\mathbf W_q\\in\\mathbb R^{h\\times d_q}$, and $\\mathbf v\\in\\mathbb R^{p}$:\n",
        "\n",
        "$$\\alpha(\\mathbf k, \\mathbf q) = \\mathbf v^T \\text{tanh}(\\mathbf W_k \\mathbf k + \\mathbf W_q\\mathbf q). $$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-22T03:29:07.744783Z",
          "start_time": "2019-04-22T03:29:07.738228Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "7"
        },
        "id": "ODv2ZA2zJ4eN"
      },
      "source": [
        "class MLPAttention(nn.Block):  # This class is saved in d2l. \n",
        "    def __init__(self, units, dropout, **kwargs):\n",
        "        super(MLPAttention, self).__init__(**kwargs)\n",
        "        # Use flatten=True to keep query's and key's 3-D shapes.   \n",
        "        self.W_k = nn.Dense(units, activation='tanh', \n",
        "                            use_bias=False, flatten=False)\n",
        "        self.W_q = nn.Dense(units, activation='tanh', \n",
        "                            use_bias=False, flatten=False)\n",
        "        self.v = nn.Dense(1, use_bias=False, flatten=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, valid_length):\n",
        "        query, key = self.W_k(query), self.W_q(key)\n",
        "        # expand query to (batch_size, #querys, 1, units), and key to \n",
        "        # (batch_size, 1, #kv_pairs, units). Then plus them with broadcast.  \n",
        "        features = query.expand_dims(axis=2) + key.expand_dims(axis=1)\n",
        "        scores = self.v(features).squeeze(axis=-1)\n",
        "        attention_weights = self.dropout(masked_softmax(scores, valid_length))\n",
        "        return nd.batch_dot(attention_weights, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnXBnjwfJ4eN"
      },
      "source": [
        "Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-22T03:29:07.757874Z",
          "start_time": "2019-04-22T03:29:07.746575Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "8"
        },
        "id": "KFF7yOwaJ4eO",
        "outputId": "e61840d0-16f3-4962-cd84-c553a645d863"
      },
      "source": [
        "atten = MLPAttention(units=8, dropout=0.1)\n",
        "atten.initialize()\n",
        "atten(nd.ones((2,1,2)), keys, values, nd.array([2, 6]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[[ 2.        3.        4.        5.      ]]\n",
              "\n",
              " [[10.       11.       12.000001 13.      ]]]\n",
              "<NDArray 2x1x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}